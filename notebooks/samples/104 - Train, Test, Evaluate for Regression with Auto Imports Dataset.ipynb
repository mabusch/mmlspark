{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 104 - Train, Test, Evaluate for Regression with Auto Imports Dataset\n",
    "\n",
    "This sample notebook is based on the Gallery \"Sample 6: Train, Test, Evaluate for Regression: Auto Imports Dataset\" for AzureML Studio. This experiment demonstrates how to build a regression model to predict the automobile's price. The process includes training, testing, and evaluating the model on the Autom Imports data set.\n",
    "\n",
    "This sample demonstrates the use of several members of the mmlspark library:\n",
    "- TrainRegressor\n",
    "- SummarizeData\n",
    "- CleanMissingData\n",
    "- ComputeStatistics\n",
    "- FindBestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mmlspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the schema for the data that will be read in. Allow all fields to be nullable, so that missing values can be handled appropriately, such as replacing them with the mean or median value for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType, StringType, DoubleType, StructType, StructField\n",
    "\n",
    "tableSchema = StructType([StructField(\"symboling\",         LongType(),   True),\n",
    "                          StructField(\"normalized-losses\", DoubleType(), True),\n",
    "                          StructField(\"make\",              StringType(), True),\n",
    "                          StructField(\"fuel-type\",         StringType(), True),\n",
    "                          StructField(\"aspiration\",        StringType(), True),\n",
    "                          StructField(\"body-style\",        StringType(), True),\n",
    "                          StructField(\"drive-wheels\",      StringType(), True),\n",
    "                          StructField(\"engine-location\",   StringType(), True),\n",
    "                          StructField(\"wheel-base\",        DoubleType(), True),\n",
    "                          StructField(\"length\",            DoubleType(), True),\n",
    "                          StructField(\"width\",             DoubleType(), True),\n",
    "                          StructField(\"height\",            DoubleType(), True),\n",
    "                          StructField(\"curb-weight\",       LongType(),   True),\n",
    "                          StructField(\"engine-type\",       StringType(), True),\n",
    "                          StructField(\"num-of-cylinders\",  StringType(), True),\n",
    "                          StructField(\"engine-size\",       LongType(),   True),\n",
    "                          StructField(\"fuel-system\",       StringType(), True),\n",
    "                          StructField(\"bore\",              DoubleType(), True),\n",
    "                          StructField(\"stroke\",            DoubleType(), True),\n",
    "                          StructField(\"compression-ratio\", DoubleType(), True),\n",
    "                          StructField(\"horsepower\",        DoubleType(), True),\n",
    "                          StructField(\"peak-rpm\",          DoubleType(), True),\n",
    "                          StructField(\"city-mpg\",          LongType(),   True),\n",
    "                          StructField(\"highway-mpg\",       LongType(),   True),\n",
    "                          StructField(\"price\",             DoubleType(), True)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Read the data from the AutomobilePriceRaw.csv file into a pandas dataframe. Specify possible reprsentations of missing values, and drop the 'num-of-doors' column as the data is read in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFile = \"AutomobilePriceRaw.csv\"\n",
    "import os, urllib\n",
    "if not os.path.isfile(dataFile):\n",
    "    urllib.request.urlretrieve(\"https://mmlspark.azureedge.net/datasets/\"+dataFile, dataFile)\n",
    "data = spark.createDataFrame(pd.read_csv(dataFile,\n",
    "                                         na_values=['',' ','?'],\n",
    "                                         usecols=lambda x: x not in ['num-of-doors']), tableSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the data using `SummarizeData` and print the summary. Note that several columns have missing values (normalized-losses, bore, stroke, horsepower, peak-rpm, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##summary = mmlspark.SummarizeData().transform(df)\n",
    "from mmlspark import SummarizeData\n",
    "summary = SummarizeData().transform(data)\n",
    "summary.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `CleanMissingData` API to replace the missing values with something more useful or meaningful. In this case, we will replace missing values in numeric columns with the median value for the column. Then, Summarize again and note the differences. Notice that all columns have 205 rows, and none of the rows contains missing values. Also, notice that the boundaries on the quartile bins have shifted slightly due to the missing value replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmlspark import CleanMissingData\n",
    "cols = [\"normalized-losses\", \"stroke\", \"bore\", \"horsepower\", \"peak-rpm\", \"price\"]\n",
    "cleanModel = CleanMissingData(cleaningMode=\"Median\", inputCols=cols, outputCols=cols).fit(data)\n",
    "data = cleanModel.transform(data)\n",
    "summary = SummarizeData().transform(data)\n",
    "summary.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data into training and testing datasets\n",
    "train, test = data.randomSplit([0.6, 0.4], seed=123)\n",
    "train.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Poisson Regression model using the `GeneralizedLinearRegressor` API from Spark and train it on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train Poisson Regression Model\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from mmlspark import TrainRegressor\n",
    "\n",
    "glr = GeneralizedLinearRegression(family=\"poisson\", link=\"log\")\n",
    "poissonModel = TrainRegressor(model=glr, labelCol=\"price\", numFeatures=256).fit(train)\n",
    "poissonPrediction = poissonModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a Random Forest Regression model using the `RandomRorestRegressor` API from spark and train it on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train Random Forest regression on the same training data:\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(maxDepth=30, maxBins=128, numTrees=8, minInstancesPerNode=1)\n",
    "randomForestModel = TrainRegressor(model=rfr, labelCol=\"price\", numFeatures=256).fit(train)\n",
    "randomForestPrediction = randomForestModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute basic statistics for the Poisson model using `ComputeModelStatistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use ComputeStatistics to evaluate the PoissonRegressor:\n",
    "from mmlspark import ComputeModelStatistics\n",
    "poissonMetrics = ComputeModelStatistics().transform(poissonPrediction)\n",
    "print(\"Poisson Metrics\")\n",
    "poissonMetrics.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, compute the statistics for the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use ComputeStatistics to evaluate the RandomForestRegresspr\"\n",
    "randomForestMetrics = ComputeModelStatistics().transform(randomForestPrediction)\n",
    "print(\"Random Forest Metrics\")\n",
    "randomForestMetrics.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which model is better, using `FindBestModel` with the `evaluationMetric` set to \"r2\", and compute the model statistics for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a given metric, find the better model\n",
    "from mmlspark import FindBestModel\n",
    "rModels = [poissonModel, randomForestModel]\n",
    "bestModel = FindBestModel(models=rModels, evaluationMetric=\"r2\").fit(test)\n",
    "prediction = bestModel.transform(test)\n",
    "statistics = ComputeModelStatistics().transform(prediction)\n",
    "statistics.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Save the best model for use in scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestModel.write().overwrite().save(\"flightDelayBestModel.mml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

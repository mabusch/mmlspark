{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 105 - Training Regressions \n",
    "\n",
    "This example notebook is similar to [Notebook 102](102 - Training Regression Algorithms with the L-BFGS Solver). In this example, we will convert data columns using `DataConversion()` instead of making them be categorical columns.\n",
    "\n",
    "This sample demonstrates how to use the following APIs:\n",
    "- `TrainRegressor`: [TrainRegressor](http://mmlspark.azureedge.net/docs/pyspark/TrainRegressor.html)\n",
    "- `ComputePerInstanceStatistics`: [ComputePerInstanceStatistics](http://mmlspark.azureedge.net/docs/pyspark/ComputePerInstanceStatistics.html)\n",
    "- `DataConversion`: [DataConversion](http://mmlspark.azureedge.net/docs/pyspark/DataConversion.html)\n",
    "\n",
    "First, import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the CSV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFile = \"On_Time_Performance_2012_9.csv\"\n",
    "import os, urllib\n",
    "if not os.path.isfile(dataFile):\n",
    "    urllib.request.urlretrieve(\"https://mmlspark.azureedge.net/datasets/\"+dataFile, dataFile)\n",
    "flightDelay = spark.createDataFrame(pd.read_csv(dataFile))\n",
    "#print some basic info\n",
    "print(\"records read: \" + str(flightDelay.count()))\n",
    "print(\"Schema: \")\n",
    "flightDelay.printSchema()\n",
    "flightDelay.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `DataConversion` API to convert the columns listed to double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmlspark import DataConversion\n",
    "flightDelay = DataConversion(col=\"Quarter,Month,DayofMonth,DayOfWeek,OriginAirportID,DestAirportID,CRSDepTime,CRSArrTime\",\n",
    "                             convertTo=\"double\").transform(flightDelay)\n",
    "flightDelay.printSchema()\n",
    "flightDelay.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the datasest into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = flightDelay.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a regressor on the dataset with l-bfgs. First, use `DataConversion` to convert the columns \"Carrier\", \"DepTimeBlk\", and \"ArrTimeBlk\" to categorical data. Recall that in Notebook 102, this was accomplished by iterating over the columns and converting the strings to index values using the `StringIndexer` API. The `DataConversion` API simplifies the task by allowing you to specify all columns that will have the same end Type in a single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmlspark import TrainRegressor, TrainedRegressorModel\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "trainCat = DataConversion(col=\"Carrier,DepTimeBlk,ArrTimeBlk\", convertTo=\"toCategorical\").transform(train)\n",
    "testCat  = DataConversion(col=\"Carrier,DepTimeBlk,ArrTimeBlk\", convertTo=\"toCategorical\").transform(test)\n",
    "lr = LinearRegression().setSolver(\"l-bfgs\").setRegParam(0.1).setElasticNetParam(0.3)\n",
    "model = TrainRegressor(model=lr, labelCol=\"ArrDelay\").fit(trainCat)\n",
    "model.write().overwrite().save(\"flightDelayModel.mml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the regressor on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flightDelayModel = TrainedRegressorModel.load(\"flightDelayModel.mml\")\n",
    "scoredData = flightDelayModel.transform(testCat)\n",
    "scoredData.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute model metrics against the entire scored dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmlspark import ComputeModelStatistics\n",
    "metrics = ComputeModelStatistics().transform(scoredData)\n",
    "metrics.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute and show per-instance statistics, demonstrating the usage of `ComputePerInstanceStatistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmlspark import ComputePerInstanceStatistics\n",
    "evalPerInstance = ComputePerInstanceStatistics().transform(scoredData)\n",
    "evalPerInstance.select(\"ArrDelay\", \"Scores\", \"L1_loss\", \"L2_loss\").limit(10).toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
